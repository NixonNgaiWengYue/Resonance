{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_1 = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\comments1.csv\")\n",
    "comments_2 = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\comments2.csv\")\n",
    "comments_3 = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\comments3.csv\")\n",
    "comments_4 = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\comments4.csv\")\n",
    "comments_5 = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\comments5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06b37a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video = pd.read_csv(r\"C:\\Users\\Nixon Ngai Weng Yue\\Downloads\\dataset\\videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate([comments_1, comments_2, comments_3, comments_4,comments_5], start=1):\n",
    "    df[\"dataset_id\"] = i\n",
    "\n",
    "df_all_comments = pd.concat([comments_1, comments_2, comments_3, comments_4,comments_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_soe(video_df, comment_df, w_video_like=1, w_fav=2, w_comment=3, w_comment_like=1):\n",
    "    k = int(video_df[\"viewCount\"].median())\n",
    "\n",
    "    video_df[\"publishedAt\"] = pd.to_datetime(video_df[\"publishedAt\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "    comment_stats = comment_df.groupby(\"videoId\").agg(\n",
    "        comment_likes_sum=(\"likeCount\", \"sum\"),\n",
    "        comment_count=(\"commentId\", \"count\")\n",
    "    ).reset_index()\n",
    "\n",
    "    merged = video_df.merge(comment_stats, on=\"videoId\", how=\"left\")\n",
    "\n",
    "    merged[\"comment_likes_sum\"] = merged[\"comment_likes_sum\"].fillna(0)\n",
    "    merged[\"comment_count\"] = merged[\"comment_count\"].fillna(0)\n",
    "\n",
    "    merged[\"engagement\"] = (\n",
    "        w_video_like * merged[\"likeCount\"] +\n",
    "        w_fav * merged[\"favouriteCount\"] +\n",
    "        w_comment * merged[\"commentCount\"] +\n",
    "        w_comment_like * merged[\"comment_likes_sum\"]\n",
    "    )\n",
    "\n",
    "    merged[\"denominator\"] = merged[\"viewCount\"] + k\n",
    "\n",
    "    merged[\"SoE\"] = merged[\"engagement\"] / merged[\"denominator\"]\n",
    "\n",
    "    comment_with_soe = comment_df.merge(\n",
    "        merged[[\"videoId\", \"SoE\"]],\n",
    "        on=\"videoId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return comment_with_soe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               kind  commentId  channelId  videoId  authorId  \\\n",
      "0   youtube#comment    1781382      14492    74288   2032536   \n",
      "1   youtube#comment     289571      14727    79618   3043229   \n",
      "2   youtube#comment     569077       3314    51826    917006   \n",
      "3   youtube#comment    2957962       5008    58298   1853470   \n",
      "4   youtube#comment     673093      21411     1265   2584166   \n",
      "5   youtube#comment    1525723      18073    69091   1915402   \n",
      "6   youtube#comment    3079259       2988    91785    885833   \n",
      "7   youtube#comment     579871      45729    66477   2775194   \n",
      "8   youtube#comment    4596873      18670    88816   1040123   \n",
      "9   youtube#comment     910365      25235    31185   1092265   \n",
      "10  youtube#comment     779733      36205    72492   3158722   \n",
      "11  youtube#comment    1204214      33644    86518   1756840   \n",
      "12  youtube#comment     957058      20162    75828   1548100   \n",
      "13  youtube#comment    4672340      29550    53751   1064748   \n",
      "14  youtube#comment    2797490       4776    57274    590651   \n",
      "15  youtube#comment    3439642      42058    80982   3499981   \n",
      "16  youtube#comment    1055950      41246    55292    785546   \n",
      "17  youtube#comment    2230760      11003    28238    593180   \n",
      "18  youtube#comment     211328      17781    87279   2454363   \n",
      "19  youtube#comment    4185450      10928    48281   1352230   \n",
      "\n",
      "                                                                                                                                                                                     textOriginal  \\\n",
      "0                                                                                                                                             PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it   \n",
      "1                                                                                                                                                Apply mashed potato juice and mixed it with curd   \n",
      "2                                                                                                                                                                      69 missed calls from marsüëΩ   \n",
      "3                                                                                                                                                                                            Baaa   \n",
      "4                                                                                                                                                 you look like raven from phenomena raven no cap   \n",
      "5                                                                                                                                                                                        American   \n",
      "6                                                                                                                                                      Sahi disha me ja ja raha india ka Future..   \n",
      "7                                                                                                                                                                                      ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§   \n",
      "8                                                                                                                                                                 Love your videos. Thank you ‚ù§‚ù§‚ù§   \n",
      "9                                                                                                                                          India is  the best and  very beautiful üòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è   \n",
      "10                                                                                                                                                                                              ‚ù§   \n",
      "11                                                                                                                                              This is so true. Skinny jeans always nipped meüò≠üò≠üò≠   \n",
      "12                                                                                                                                                                             Dunia semakin aneh   \n",
      "13                                                                                                                                                             I love korean and japanese makeup!   \n",
      "14                                                                                                                                                 Plz upload a vedio about your teeth transition   \n",
      "15                                                                                                                           Why don‚Äôt you use wigs? Or is it just better to use ur natural hair?   \n",
      "16                                                                                                                                                                                           Love   \n",
      "17  What hair oil did u use because the front of my hair a really short like yours was and I‚Äôm trying to grow it out but no hair oils are working so do u know which one u used it‚Äôs ok if don‚Äôt.   \n",
      "18                                                                           Oh, I'm so glad that you found this channel then!  Thanks so much for letting me know that the video was helpful.  ‚ù§   \n",
      "19                                                                                                                                                                             Wavy plus straight   \n",
      "\n",
      "    parentCommentId  likeCount                publishedAt  \\\n",
      "0               NaN          0  2023-08-15 21:48:52+00:00   \n",
      "1         3198066.0          0  2023-10-02 13:08:22+00:00   \n",
      "2               NaN          0  2024-05-31 12:03:12+00:00   \n",
      "3               NaN          0  2024-02-13 15:48:37+00:00   \n",
      "4               NaN          0  2020-02-15 22:28:44+00:00   \n",
      "5               NaN          0  2023-01-17 12:50:08+00:00   \n",
      "6               NaN          0  2021-09-03 06:51:48+00:00   \n",
      "7               NaN          0  2025-01-17 22:08:38+00:00   \n",
      "8               NaN          1  2023-06-24 07:24:06+00:00   \n",
      "9               NaN          0  2025-02-27 14:49:22+00:00   \n",
      "10              NaN          1  2023-04-11 07:02:06+00:00   \n",
      "11              NaN          1  2023-06-16 15:14:54+00:00   \n",
      "12              NaN          0  2023-04-28 04:13:47+00:00   \n",
      "13              NaN          0  2025-01-25 05:27:14+00:00   \n",
      "14              NaN          0  2025-02-07 03:57:52+00:00   \n",
      "15              NaN          0  2025-01-24 18:31:34+00:00   \n",
      "16              NaN          1  2022-05-08 07:01:29+00:00   \n",
      "17              NaN          0  2024-08-08 01:47:19+00:00   \n",
      "18        3686870.0          1  2023-05-09 04:40:28+00:00   \n",
      "19              NaN          0  2025-05-29 19:04:23+00:00   \n",
      "\n",
      "                    updatedAt  dataset_id       SoE  \n",
      "0   2023-08-15 21:48:52+00:00           1  0.034254  \n",
      "1   2023-10-02 13:08:22+00:00           1  0.048488  \n",
      "2   2024-05-31 12:03:12+00:00           1  0.027266  \n",
      "3   2024-02-13 15:48:37+00:00           1  0.086262  \n",
      "4   2020-02-15 22:28:44+00:00           1  0.089835  \n",
      "5   2023-01-17 12:50:08+00:00           1  0.034362  \n",
      "6   2021-09-03 06:51:48+00:00           1  0.017975  \n",
      "7   2025-01-17 22:08:38+00:00           1  0.035624  \n",
      "8   2023-06-24 07:24:06+00:00           1  0.016916  \n",
      "9   2025-02-27 14:49:22+00:00           1  0.034845  \n",
      "10  2023-04-11 07:02:06+00:00           1  0.029876  \n",
      "11  2023-06-16 15:14:54+00:00           1  0.071154  \n",
      "12  2023-04-28 04:13:47+00:00           1       NaN  \n",
      "13  2025-01-25 05:27:14+00:00           1  0.089267  \n",
      "14  2025-02-07 03:57:52+00:00           1  0.040324  \n",
      "15  2025-01-24 18:31:34+00:00           1  0.031497  \n",
      "16  2022-05-08 07:01:29+00:00           1  0.048882  \n",
      "17  2024-08-08 01:47:19+00:00           1  0.054947  \n",
      "18  2023-05-09 04:40:28+00:00           1  0.053568  \n",
      "19  2025-05-29 19:04:23+00:00           1  0.037430  \n"
     ]
    }
   ],
   "source": [
    "result_soe = compute_soe(df_video, df_all_comments)\n",
    "print(result_soe.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_depth(comment_id, parent_map):\n",
    "    depth = 0\n",
    "    parent = parent_map.get(comment_id, None)\n",
    "    while parent is not None:\n",
    "        depth += 1\n",
    "        parent = parent_map.get(parent, None)\n",
    "    return depth\n",
    "\n",
    "def compute_depths(df):\n",
    "    df = df.copy()\n",
    "    if \"commentId\" not in df.columns or \"parentCommentId\" not in df.columns:\n",
    "        raise KeyError(\"DataFrame must contain 'commentId' and 'parentCommentId' columns\")\n",
    "    parent_map = df.set_index(\"commentId\")[\"parentCommentId\"].to_dict()\n",
    "    df[\"depth\"] = df[\"commentId\"].apply(lambda cid: get_comment_depth(cid, parent_map))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61c24908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               kind  commentId  channelId  videoId  authorId  \\\n",
      "0   youtube#comment    1781382      14492    74288   2032536   \n",
      "1   youtube#comment     289571      14727    79618   3043229   \n",
      "2   youtube#comment     569077       3314    51826    917006   \n",
      "3   youtube#comment    2957962       5008    58298   1853470   \n",
      "4   youtube#comment     673093      21411     1265   2584166   \n",
      "5   youtube#comment    1525723      18073    69091   1915402   \n",
      "6   youtube#comment    3079259       2988    91785    885833   \n",
      "7   youtube#comment     579871      45729    66477   2775194   \n",
      "8   youtube#comment    4596873      18670    88816   1040123   \n",
      "9   youtube#comment     910365      25235    31185   1092265   \n",
      "10  youtube#comment     779733      36205    72492   3158722   \n",
      "11  youtube#comment    1204214      33644    86518   1756840   \n",
      "12  youtube#comment     957058      20162    75828   1548100   \n",
      "13  youtube#comment    4672340      29550    53751   1064748   \n",
      "14  youtube#comment    2797490       4776    57274    590651   \n",
      "15  youtube#comment    3439642      42058    80982   3499981   \n",
      "16  youtube#comment    1055950      41246    55292    785546   \n",
      "17  youtube#comment    2230760      11003    28238    593180   \n",
      "18  youtube#comment     211328      17781    87279   2454363   \n",
      "19  youtube#comment    4185450      10928    48281   1352230   \n",
      "\n",
      "                                                                                                                                                                                     textOriginal  \\\n",
      "0                                                                                                                                             PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it   \n",
      "1                                                                                                                                                Apply mashed potato juice and mixed it with curd   \n",
      "2                                                                                                                                                                      69 missed calls from marsüëΩ   \n",
      "3                                                                                                                                                                                            Baaa   \n",
      "4                                                                                                                                                 you look like raven from phenomena raven no cap   \n",
      "5                                                                                                                                                                                        American   \n",
      "6                                                                                                                                                      Sahi disha me ja ja raha india ka Future..   \n",
      "7                                                                                                                                                                                      ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§   \n",
      "8                                                                                                                                                                 Love your videos. Thank you ‚ù§‚ù§‚ù§   \n",
      "9                                                                                                                                          India is  the best and  very beautiful üòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è   \n",
      "10                                                                                                                                                                                              ‚ù§   \n",
      "11                                                                                                                                              This is so true. Skinny jeans always nipped meüò≠üò≠üò≠   \n",
      "12                                                                                                                                                                             Dunia semakin aneh   \n",
      "13                                                                                                                                                             I love korean and japanese makeup!   \n",
      "14                                                                                                                                                 Plz upload a vedio about your teeth transition   \n",
      "15                                                                                                                           Why don‚Äôt you use wigs? Or is it just better to use ur natural hair?   \n",
      "16                                                                                                                                                                                           Love   \n",
      "17  What hair oil did u use because the front of my hair a really short like yours was and I‚Äôm trying to grow it out but no hair oils are working so do u know which one u used it‚Äôs ok if don‚Äôt.   \n",
      "18                                                                           Oh, I'm so glad that you found this channel then!  Thanks so much for letting me know that the video was helpful.  ‚ù§   \n",
      "19                                                                                                                                                                             Wavy plus straight   \n",
      "\n",
      "    parentCommentId  likeCount                publishedAt  \\\n",
      "0               NaN          0  2023-08-15 21:48:52+00:00   \n",
      "1         3198066.0          0  2023-10-02 13:08:22+00:00   \n",
      "2               NaN          0  2024-05-31 12:03:12+00:00   \n",
      "3               NaN          0  2024-02-13 15:48:37+00:00   \n",
      "4               NaN          0  2020-02-15 22:28:44+00:00   \n",
      "5               NaN          0  2023-01-17 12:50:08+00:00   \n",
      "6               NaN          0  2021-09-03 06:51:48+00:00   \n",
      "7               NaN          0  2025-01-17 22:08:38+00:00   \n",
      "8               NaN          1  2023-06-24 07:24:06+00:00   \n",
      "9               NaN          0  2025-02-27 14:49:22+00:00   \n",
      "10              NaN          1  2023-04-11 07:02:06+00:00   \n",
      "11              NaN          1  2023-06-16 15:14:54+00:00   \n",
      "12              NaN          0  2023-04-28 04:13:47+00:00   \n",
      "13              NaN          0  2025-01-25 05:27:14+00:00   \n",
      "14              NaN          0  2025-02-07 03:57:52+00:00   \n",
      "15              NaN          0  2025-01-24 18:31:34+00:00   \n",
      "16              NaN          1  2022-05-08 07:01:29+00:00   \n",
      "17              NaN          0  2024-08-08 01:47:19+00:00   \n",
      "18        3686870.0          1  2023-05-09 04:40:28+00:00   \n",
      "19              NaN          0  2025-05-29 19:04:23+00:00   \n",
      "\n",
      "                    updatedAt  dataset_id  depth  \n",
      "0   2023-08-15 21:48:52+00:00           1      1  \n",
      "1   2023-10-02 13:08:22+00:00           1      2  \n",
      "2   2024-05-31 12:03:12+00:00           1      1  \n",
      "3   2024-02-13 15:48:37+00:00           1      1  \n",
      "4   2020-02-15 22:28:44+00:00           1      1  \n",
      "5   2023-01-17 12:50:08+00:00           1      1  \n",
      "6   2021-09-03 06:51:48+00:00           1      1  \n",
      "7   2025-01-17 22:08:38+00:00           1      1  \n",
      "8   2023-06-24 07:24:06+00:00           1      1  \n",
      "9   2025-02-27 14:49:22+00:00           1      1  \n",
      "10  2023-04-11 07:02:06+00:00           1      1  \n",
      "11  2023-06-16 15:14:54+00:00           1      1  \n",
      "12  2023-04-28 04:13:47+00:00           1      1  \n",
      "13  2025-01-25 05:27:14+00:00           1      1  \n",
      "14  2025-02-07 03:57:52+00:00           1      1  \n",
      "15  2025-01-24 18:31:34+00:00           1      1  \n",
      "16  2022-05-08 07:01:29+00:00           1      1  \n",
      "17  2024-08-08 01:47:19+00:00           1      1  \n",
      "18  2023-05-09 04:40:28+00:00           1      2  \n",
      "19  2025-05-29 19:04:23+00:00           1      1  \n"
     ]
    }
   ],
   "source": [
    "result_compute_depths = compute_depths(df_all_comments)\n",
    "print(result_compute_depths.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca30fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_reply_factor(df, depth_weight=0.5):\n",
    "    df = df.copy()\n",
    "    if \"depth\" not in df.columns:\n",
    "        df = compute_depths(df)\n",
    "\n",
    "    reply_counts = df[\"parentCommentId\"].value_counts().to_dict()\n",
    "    df[\"numReplies\"] = df[\"commentId\"].map(reply_counts).fillna(0).astype(int)\n",
    "\n",
    "    df[\"ReplyFactor\"] = (1 + depth_weight * df[\"depth\"]) * (1 + np.log1p(df[\"numReplies\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              kind  commentId  channelId  videoId  authorId  \\\n",
      "0  youtube#comment    1781382      14492    74288   2032536   \n",
      "1  youtube#comment     289571      14727    79618   3043229   \n",
      "2  youtube#comment     569077       3314    51826    917006   \n",
      "3  youtube#comment    2957962       5008    58298   1853470   \n",
      "4  youtube#comment     673093      21411     1265   2584166   \n",
      "\n",
      "                                          textOriginal  parentCommentId  \\\n",
      "0  PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it              NaN   \n",
      "1     Apply mashed potato juice and mixed it with curd        3198066.0   \n",
      "2                           69 missed calls from marsüëΩ              NaN   \n",
      "3                                                 Baaa              NaN   \n",
      "4      you look like raven from phenomena raven no cap              NaN   \n",
      "\n",
      "   likeCount                publishedAt                  updatedAt  \\\n",
      "0          0  2023-08-15 21:48:52+00:00  2023-08-15 21:48:52+00:00   \n",
      "1          0  2023-10-02 13:08:22+00:00  2023-10-02 13:08:22+00:00   \n",
      "2          0  2024-05-31 12:03:12+00:00  2024-05-31 12:03:12+00:00   \n",
      "3          0  2024-02-13 15:48:37+00:00  2024-02-13 15:48:37+00:00   \n",
      "4          0  2020-02-15 22:28:44+00:00  2020-02-15 22:28:44+00:00   \n",
      "\n",
      "   dataset_id  depth  numReplies  ReplyFactor  \n",
      "0           1      1           1     2.539721  \n",
      "1           1      2           0     2.000000  \n",
      "2           1      1           0     1.500000  \n",
      "3           1      1           0     1.500000  \n",
      "4           1      1           0     1.500000  \n"
     ]
    }
   ],
   "source": [
    "result_reply_factor = compute_reply_factor(df_all_comments,depth_weight=0.5)\n",
    "print(result_reply_factor.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_relevance_by_video(video_df, comment_df, text_col=\"textOriginal\",\n",
    "                                 video_meta_cols=(\"title\",\"description\",\"tags\")):\n",
    "    comment_df = comment_df.copy()\n",
    "\n",
    "    for c in (\"videoId\", text_col, \"commentId\"):\n",
    "        if c not in comment_df.columns:\n",
    "            raise KeyError(f\"comment_df must contain column '{c}'\")\n",
    "    for c in (\"videoId\",) + video_meta_cols:\n",
    "        if c not in video_df.columns:\n",
    "            raise KeyError(f\"video_df must contain column '{c}'\")\n",
    "\n",
    "    video_df = video_df.copy()\n",
    "    video_df[\"video_meta\"] = (\n",
    "        video_df[video_meta_cols[0]].fillna(\"\").astype(str) + \" \" +\n",
    "        video_df[video_meta_cols[1]].fillna(\"\").astype(str) + \" \" +\n",
    "        video_df[video_meta_cols[2]].fillna(\"\").astype(str)\n",
    "    )\n",
    "    video_meta_map = dict(zip(video_df[\"videoId\"], video_df[\"video_meta\"]))\n",
    "\n",
    "    relevances = np.zeros(len(comment_df), dtype=float)\n",
    "\n",
    "    for vid, group in comment_df.groupby(\"videoId\", sort=False):\n",
    "        idx = group.index\n",
    "        video_text = str(video_meta_map.get(vid, \"\")).strip()\n",
    "        comments = group[text_col].fillna(\"\").astype(str).str.strip().tolist()\n",
    "\n",
    "        if (not video_text) or all(not c for c in comments):\n",
    "            continue \n",
    "\n",
    "        try:\n",
    "            texts = comments + [video_text]   \n",
    "            vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "            vectors = vectorizer.fit_transform(texts)\n",
    "            comment_vecs = vectors[:-1]   \n",
    "            video_vec = vectors[-1]\n",
    "\n",
    "            sims = cosine_similarity(comment_vecs, video_vec).reshape(-1)\n",
    "            sims = np.clip(sims, 0.0, 1.0)\n",
    "            relevances[idx] = sims\n",
    "\n",
    "        except ValueError:\n",
    "            relevances[idx] = 0.0\n",
    "\n",
    "    comment_df[\"relevance\"] = relevances\n",
    "    return comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c744f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              kind  commentId  channelId  videoId  authorId  \\\n",
      "0  youtube#comment    1781382      14492    74288   2032536   \n",
      "1  youtube#comment     289571      14727    79618   3043229   \n",
      "2  youtube#comment     569077       3314    51826    917006   \n",
      "3  youtube#comment    2957962       5008    58298   1853470   \n",
      "4  youtube#comment     673093      21411     1265   2584166   \n",
      "\n",
      "                                          textOriginal  parentCommentId  \\\n",
      "0  PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it              NaN   \n",
      "1     Apply mashed potato juice and mixed it with curd        3198066.0   \n",
      "2                           69 missed calls from marsüëΩ              NaN   \n",
      "3                                                 Baaa              NaN   \n",
      "4      you look like raven from phenomena raven no cap              NaN   \n",
      "\n",
      "   likeCount                publishedAt                  updatedAt  \\\n",
      "0          0  2023-08-15 21:48:52+00:00  2023-08-15 21:48:52+00:00   \n",
      "1          0  2023-10-02 13:08:22+00:00  2023-10-02 13:08:22+00:00   \n",
      "2          0  2024-05-31 12:03:12+00:00  2024-05-31 12:03:12+00:00   \n",
      "3          0  2024-02-13 15:48:37+00:00  2024-02-13 15:48:37+00:00   \n",
      "4          0  2020-02-15 22:28:44+00:00  2020-02-15 22:28:44+00:00   \n",
      "\n",
      "   dataset_id  relevance  \n",
      "0           1   0.076233  \n",
      "1           1   0.008955  \n",
      "2           1   0.000000  \n",
      "3           1   0.000000  \n",
      "4           1   0.001714  \n"
     ]
    }
   ],
   "source": [
    "result_relevance = calculate_relevance_by_video(df_video,df_all_comments)\n",
    "print(result_relevance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b944e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_norm(video_df, comment_df, tz=\"UTC\"):\n",
    "    today = pd.Timestamp.now(tz=tz)\n",
    "\n",
    "    video_df = video_df.copy()\n",
    "    comment_df = comment_df.copy()\n",
    "    video_df[\"publishedAt\"] = pd.to_datetime(video_df[\"publishedAt\"], errors=\"coerce\", utc=True)\n",
    "    comment_df[\"publishedAt\"] = pd.to_datetime(comment_df[\"publishedAt\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "    comment_df[\"days_since_comment\"] = (today - comment_df[\"publishedAt\"]).dt.days\n",
    "\n",
    "    max_days_comment = comment_df[\"days_since_comment\"].max()\n",
    "\n",
    "    if max_days_comment == 0 or pd.isna(max_days_comment):\n",
    "        comment_df[\"timeNorm\"] = 1.0\n",
    "    else:\n",
    "        comment_df[\"timeNorm\"] = 1 - (comment_df[\"days_since_comment\"] / max_days_comment)\n",
    "        comment_df[\"timeNorm\"] = comment_df[\"timeNorm\"].fillna(1.0)\n",
    "\n",
    "    return comment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdcf4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               kind  commentId  channelId  videoId  authorId  \\\n",
      "0   youtube#comment    1781382      14492    74288   2032536   \n",
      "1   youtube#comment     289571      14727    79618   3043229   \n",
      "2   youtube#comment     569077       3314    51826    917006   \n",
      "3   youtube#comment    2957962       5008    58298   1853470   \n",
      "4   youtube#comment     673093      21411     1265   2584166   \n",
      "5   youtube#comment    1525723      18073    69091   1915402   \n",
      "6   youtube#comment    3079259       2988    91785    885833   \n",
      "7   youtube#comment     579871      45729    66477   2775194   \n",
      "8   youtube#comment    4596873      18670    88816   1040123   \n",
      "9   youtube#comment     910365      25235    31185   1092265   \n",
      "10  youtube#comment     779733      36205    72492   3158722   \n",
      "11  youtube#comment    1204214      33644    86518   1756840   \n",
      "12  youtube#comment     957058      20162    75828   1548100   \n",
      "13  youtube#comment    4672340      29550    53751   1064748   \n",
      "14  youtube#comment    2797490       4776    57274    590651   \n",
      "15  youtube#comment    3439642      42058    80982   3499981   \n",
      "16  youtube#comment    1055950      41246    55292    785546   \n",
      "17  youtube#comment    2230760      11003    28238    593180   \n",
      "18  youtube#comment     211328      17781    87279   2454363   \n",
      "19  youtube#comment    4185450      10928    48281   1352230   \n",
      "\n",
      "                                                                                                                                                                                     textOriginal  \\\n",
      "0                                                                                                                                             PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it   \n",
      "1                                                                                                                                                Apply mashed potato juice and mixed it with curd   \n",
      "2                                                                                                                                                                      69 missed calls from marsüëΩ   \n",
      "3                                                                                                                                                                                            Baaa   \n",
      "4                                                                                                                                                 you look like raven from phenomena raven no cap   \n",
      "5                                                                                                                                                                                        American   \n",
      "6                                                                                                                                                      Sahi disha me ja ja raha india ka Future..   \n",
      "7                                                                                                                                                                                      ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§   \n",
      "8                                                                                                                                                                 Love your videos. Thank you ‚ù§‚ù§‚ù§   \n",
      "9                                                                                                                                          India is  the best and  very beautiful üòçüòçüòçüòçüòçüòçüòç‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è   \n",
      "10                                                                                                                                                                                              ‚ù§   \n",
      "11                                                                                                                                              This is so true. Skinny jeans always nipped meüò≠üò≠üò≠   \n",
      "12                                                                                                                                                                             Dunia semakin aneh   \n",
      "13                                                                                                                                                             I love korean and japanese makeup!   \n",
      "14                                                                                                                                                 Plz upload a vedio about your teeth transition   \n",
      "15                                                                                                                           Why don‚Äôt you use wigs? Or is it just better to use ur natural hair?   \n",
      "16                                                                                                                                                                                           Love   \n",
      "17  What hair oil did u use because the front of my hair a really short like yours was and I‚Äôm trying to grow it out but no hair oils are working so do u know which one u used it‚Äôs ok if don‚Äôt.   \n",
      "18                                                                           Oh, I'm so glad that you found this channel then!  Thanks so much for letting me know that the video was helpful.  ‚ù§   \n",
      "19                                                                                                                                                                             Wavy plus straight   \n",
      "\n",
      "    parentCommentId  likeCount               publishedAt  \\\n",
      "0               NaN          0 2023-08-15 21:48:52+00:00   \n",
      "1         3198066.0          0 2023-10-02 13:08:22+00:00   \n",
      "2               NaN          0 2024-05-31 12:03:12+00:00   \n",
      "3               NaN          0 2024-02-13 15:48:37+00:00   \n",
      "4               NaN          0 2020-02-15 22:28:44+00:00   \n",
      "5               NaN          0 2023-01-17 12:50:08+00:00   \n",
      "6               NaN          0 2021-09-03 06:51:48+00:00   \n",
      "7               NaN          0 2025-01-17 22:08:38+00:00   \n",
      "8               NaN          1 2023-06-24 07:24:06+00:00   \n",
      "9               NaN          0 2025-02-27 14:49:22+00:00   \n",
      "10              NaN          1 2023-04-11 07:02:06+00:00   \n",
      "11              NaN          1 2023-06-16 15:14:54+00:00   \n",
      "12              NaN          0 2023-04-28 04:13:47+00:00   \n",
      "13              NaN          0 2025-01-25 05:27:14+00:00   \n",
      "14              NaN          0 2025-02-07 03:57:52+00:00   \n",
      "15              NaN          0 2025-01-24 18:31:34+00:00   \n",
      "16              NaN          1 2022-05-08 07:01:29+00:00   \n",
      "17              NaN          0 2024-08-08 01:47:19+00:00   \n",
      "18        3686870.0          1 2023-05-09 04:40:28+00:00   \n",
      "19              NaN          0 2025-05-29 19:04:23+00:00   \n",
      "\n",
      "                    updatedAt  dataset_id  days_since_comment  timeNorm  \n",
      "0   2023-08-15 21:48:52+00:00           1                 758  0.635752  \n",
      "1   2023-10-02 13:08:22+00:00           1                 711  0.658337  \n",
      "2   2024-05-31 12:03:12+00:00           1                 469  0.774628  \n",
      "3   2024-02-13 15:48:37+00:00           1                 577  0.722729  \n",
      "4   2020-02-15 22:28:44+00:00           1                2035  0.022105  \n",
      "5   2023-01-17 12:50:08+00:00           1                 969  0.534358  \n",
      "6   2021-09-03 06:51:48+00:00           1                1470  0.293609  \n",
      "7   2025-01-17 22:08:38+00:00           1                 237  0.886112  \n",
      "8   2023-06-24 07:24:06+00:00           1                 811  0.610284  \n",
      "9   2025-02-27 14:49:22+00:00           1                 197  0.905334  \n",
      "10  2023-04-11 07:02:06+00:00           1                 885  0.574724  \n",
      "11  2023-06-16 15:14:54+00:00           1                 819  0.606439  \n",
      "12  2023-04-28 04:13:47+00:00           1                 868  0.582893  \n",
      "13  2025-01-25 05:27:14+00:00           1                 230  0.889476  \n",
      "14  2025-02-07 03:57:52+00:00           1                 217  0.895723  \n",
      "15  2025-01-24 18:31:34+00:00           1                 230  0.889476  \n",
      "16  2022-05-08 07:01:29+00:00           1                1223  0.412302  \n",
      "17  2024-08-08 01:47:19+00:00           1                 400  0.807785  \n",
      "18  2023-05-09 04:40:28+00:00           1                 857  0.588179  \n",
      "19  2025-05-29 19:04:23+00:00           1                 105  0.949543  \n"
     ]
    }
   ],
   "source": [
    "result_time_norm = compute_time_norm(df_video,df_all_comments,tz=\"UTC\")\n",
    "print(result_time_norm.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ba7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def train_weights(df, target_col=\"likeCount\", log_transform=True, cv_folds=5):\n",
    "    required_cols = [\"SoE\", \"ReplyFactor\", \"relevance\"]\n",
    "\n",
    "    for col in required_cols + [target_col]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing from dataframe\")\n",
    "\n",
    "    X = df[required_cols].fillna(0)\n",
    "    y = df[target_col].fillna(0)\n",
    "\n",
    "    if log_transform:\n",
    "        y = np.log1p(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_scaled, y)\n",
    "\n",
    "    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring=\"r2\")\n",
    "\n",
    "    results = pd.DataFrame([\n",
    "        {\"Item\": \"Model\", \"Value\": model},\n",
    "        {\"Item\": \"Scaler\", \"Value\": scaler},\n",
    "        {\"Item\": \"Intercept\", \"Value\": model.intercept_},\n",
    "        {\"Item\": \"CV_Scores\", \"Value\": cv_scores},\n",
    "        {\"Item\": \"CV_Mean\", \"Value\": np.mean(cv_scores)},\n",
    "    ])\n",
    "\n",
    "    for feature, weight in zip(required_cols, model.coef_):\n",
    "        results = pd.concat([results, pd.DataFrame([{\"Item\": feature, \"Value\": weight}])],\n",
    "                            ignore_index=True)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_results(soe_results_df, reply_factor_results_df, relevance_relevance_df,time_norm_df):\n",
    "    merged = soe_results_df.copy()\n",
    "    merged = merged.merge(\n",
    "        reply_factor_results_df[[\"commentId\", \"ReplyFactor\"]],\n",
    "        on=\"commentId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged = merged.merge(\n",
    "        relevance_relevance_df[[\"commentId\", \"relevance\"]],\n",
    "        on=\"commentId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged = merged.merge(\n",
    "        time_norm_df[[\"commentId\", \"timeNorm\"]],\n",
    "        on=\"commentId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6829cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4725012 entries, 0 to 4725011\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   kind             object \n",
      " 1   commentId        int64  \n",
      " 2   channelId        int64  \n",
      " 3   videoId          int64  \n",
      " 4   authorId         int64  \n",
      " 5   textOriginal     object \n",
      " 6   parentCommentId  float64\n",
      " 7   likeCount        int64  \n",
      " 8   publishedAt      object \n",
      " 9   updatedAt        object \n",
      " 10  dataset_id       int64  \n",
      " 11  SoE              float64\n",
      " 12  ReplyFactor      float64\n",
      " 13  relevance        float64\n",
      " 14  timeNorm         float64\n",
      "dtypes: float64(5), int64(6), object(4)\n",
      "memory usage: 540.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_all_results(result_soe, result_reply_factor, result_relevance,result_time_norm)\n",
    "print(merged_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008940814968675291\n",
      "Index(['Item', 'Value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "results_weight = train_weights(merged_df, target_col=\"likeCount\")\n",
    "soe_value = results_weight.loc[results_weight[\"Item\"] == \"SoE\", \"Value\"].values[0]\n",
    "print(soe_value)\n",
    "print(results_weight.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_score(merged_df, weights):\n",
    "    \"\"\"\n",
    "    Compute final score using learned weights from regression.\n",
    "\n",
    "    Formula:\n",
    "        FinalScore = intercept + (a*SoE + b*ReplyFactor + c*Relevance) * (TimeNorm if enabled)\n",
    "\n",
    "    Parameters:\n",
    "        merged_df : pd.DataFrame\n",
    "            Must contain columns: SoE, ReplyFactor, relevance\n",
    "        weights : dict\n",
    "            Learned weights, e.g. {\"SoE\": 0.0089, \"ReplyFactor\": 0.3491, \"relevance\": 0.0269}\n",
    "        intercept : float\n",
    "            Learned intercept (default=0.0 if ignored)\n",
    "        use_time_norm : bool\n",
    "            Whether to multiply by TimeNorm if available in merged_df\n",
    "    \"\"\"\n",
    "    soe_weight_value = weights.loc[weights[\"Item\"] == \"SoE\", \"Value\"].values[0]\n",
    "    reply_factor_weight_value = weights.loc[weights[\"Item\"] == \"ReplyFactor\", \"Value\"].values[0]\n",
    "    relevance_weight_value = weights.loc[weights[\"Item\"] == \"relevance\", \"Value\"].values[0]\n",
    "\n",
    "    score = (\n",
    "        soe_weight_value * merged_df[\"SoE\"]\n",
    "        + reply_factor_weight_value * merged_df[\"ReplyFactor\"]\n",
    "        +relevance_weight_value * merged_df[\"relevance\"]\n",
    "    )\n",
    "\n",
    "    score = score * merged_df[\"timeNorm\"]\n",
    "\n",
    "    merged_df[\"FinalScore\"] = score\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          commentId     channelId       videoId      authorId  \\\n",
      "count  4.725012e+06  4.725012e+06  4.725012e+06  4.725012e+06   \n",
      "mean   2.362507e+06  2.677102e+04  4.699673e+04  1.820729e+06   \n",
      "std    1.363995e+06  1.503666e+04  2.593627e+04  1.053868e+06   \n",
      "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    1.181254e+06  1.449200e+04  2.597800e+04  9.060968e+05   \n",
      "50%    2.362506e+06  2.542500e+04  4.709600e+04  1.813632e+06   \n",
      "75%    3.543761e+06  4.061800e+04  6.944500e+04  2.731818e+06   \n",
      "max    4.725015e+06  5.367700e+04  9.285400e+04  3.659440e+06   \n",
      "\n",
      "       parentCommentId     likeCount    dataset_id           SoE  \\\n",
      "count     5.161350e+05  4.725012e+06  4.725012e+06  4.471305e+06   \n",
      "mean      2.623663e+06  1.012744e+01  2.883605e+00  5.110901e-02   \n",
      "std       1.215428e+06  5.444689e+02  1.367501e+00  6.220686e-02   \n",
      "min       5.161510e+05  0.000000e+00  1.000000e+00  0.000000e+00   \n",
      "25%       1.569545e+06  0.000000e+00  2.000000e+00  3.014186e-02   \n",
      "50%       2.625877e+06  0.000000e+00  3.000000e+00  4.414326e-02   \n",
      "75%       3.677645e+06  0.000000e+00  4.000000e+00  6.224738e-02   \n",
      "max       4.725006e+06  4.561420e+05  5.000000e+00  1.180268e+01   \n",
      "\n",
      "        ReplyFactor     relevance      timeNorm    FinalScore  \n",
      "count  4.725012e+06  4.725012e+06  4.725012e+06  4.471305e+06  \n",
      "mean   1.644440e+00  2.485385e-02  6.499720e-01  3.680562e-01  \n",
      "std    3.812591e-01  5.162430e-02  2.342203e-01  1.568140e-01  \n",
      "min    1.500000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    1.500000e+00  0.000000e+00  5.223450e-01  2.821900e-01  \n",
      "50%    1.500000e+00  0.000000e+00  6.785199e-01  3.707133e-01  \n",
      "75%    1.500000e+00  3.117165e-02  8.476694e-01  4.667731e-01  \n",
      "max    4.418865e+00  1.000000e+00  9.745315e-01  1.471059e+00  \n"
     ]
    }
   ],
   "source": [
    "results_final_score = compute_final_score(merged_df, results_weight)\n",
    "print(results_final_score.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f01e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_z_score(final_score_df):\n",
    "    mean_final_score = final_score_df[\"FinalScore\"].mean()\n",
    "    std_dev_final_score = final_score_df[\"FinalScore\"].std()\n",
    "\n",
    "    if std_dev_final_score == 0:\n",
    "        final_score_df[\"z_score\"] = 0\n",
    "    else:\n",
    "        final_score_df[\"z_score\"] = (final_score_df[\"FinalScore\"] - mean_final_score) / std_dev_final_score\n",
    "\n",
    "    final_score_df[\"QualityCategory\"] = pd.cut(\n",
    "        final_score_df[\"z_score\"],\n",
    "        bins=[-float(\"inf\"), -1, 1, float(\"inf\")],\n",
    "        labels=[\"Low Quality\", \"Average Quality\", \"High Quality\"]\n",
    "    )\n",
    "\n",
    "    return final_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c978fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    kind  commentId  channelId  videoId  authorId  \\\n",
      "0        youtube#comment    1781382      14492    74288   2032536   \n",
      "1        youtube#comment     289571      14727    79618   3043229   \n",
      "2        youtube#comment     569077       3314    51826    917006   \n",
      "3        youtube#comment    2957962       5008    58298   1853470   \n",
      "4        youtube#comment     673093      21411     1265   2584166   \n",
      "...                  ...        ...        ...      ...       ...   \n",
      "4725007  youtube#comment     561138      38699    90586    908808   \n",
      "4725008  youtube#comment     252294      28584    61196   3255355   \n",
      "4725009  youtube#comment    2861216      51200     7448    878070   \n",
      "4725010  youtube#comment    4145588      38313    88044   2609812   \n",
      "4725011  youtube#comment     793854      16475    52479   1713655   \n",
      "\n",
      "                                                                                                                                                                                      textOriginal  \\\n",
      "0                                                                                                                                              PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it   \n",
      "1                                                                                                                                                 Apply mashed potato juice and mixed it with curd   \n",
      "2                                                                                                                                                                       69 missed calls from marsüëΩ   \n",
      "3                                                                                                                                                                                             Baaa   \n",
      "4                                                                                                                                                  you look like raven from phenomena raven no cap   \n",
      "...                                                                                                                                                                                            ...   \n",
      "4725007                                                                                                                                                                              ÿÆ€åŸÑ€å ÿÆŸàÿ¥⁄ØŸÑŸá‚ù§‚ù§   \n",
      "4725008                                                                                                                                                                  ‚Äã@@jhanvibhatiathnkuu diüòä   \n",
      "4725009                                                                                                                                                                                         ‚ù§‚ù§   \n",
      "4725010  I think what you do is wonderful and amazing. Especially in this day. Woman want the truth not bullsh$t. If only a few brands want to work with you at least you know they have integrity   \n",
      "4725011                                                                                                                                                                          THE EYE BROWSü§¢ü§¢ü§¢ü§¢   \n",
      "\n",
      "         parentCommentId  likeCount                publishedAt  \\\n",
      "0                    NaN          0  2023-08-15 21:48:52+00:00   \n",
      "1              3198066.0          0  2023-10-02 13:08:22+00:00   \n",
      "2                    NaN          0  2024-05-31 12:03:12+00:00   \n",
      "3                    NaN          0  2024-02-13 15:48:37+00:00   \n",
      "4                    NaN          0  2020-02-15 22:28:44+00:00   \n",
      "...                  ...        ...                        ...   \n",
      "4725007              NaN          0  2024-11-11 14:39:07+00:00   \n",
      "4725008        3163061.0          0  2023-07-13 03:55:23+00:00   \n",
      "4725009              NaN          0  2025-01-07 10:59:30+00:00   \n",
      "4725010              NaN          0  2023-08-14 02:12:30+00:00   \n",
      "4725011              NaN          0  2023-02-03 07:52:12+00:00   \n",
      "\n",
      "                         updatedAt  dataset_id       SoE  ReplyFactor  \\\n",
      "0        2023-08-15 21:48:52+00:00           1  0.034254     2.539721   \n",
      "1        2023-10-02 13:08:22+00:00           1  0.048488     2.000000   \n",
      "2        2024-05-31 12:03:12+00:00           1  0.027266     1.500000   \n",
      "3        2024-02-13 15:48:37+00:00           1  0.086262     1.500000   \n",
      "4        2020-02-15 22:28:44+00:00           1  0.089835     1.500000   \n",
      "...                            ...         ...       ...          ...   \n",
      "4725007  2024-11-11 14:39:07+00:00           5  0.040303     1.500000   \n",
      "4725008  2024-06-13 22:10:28+00:00           5  0.055773     2.000000   \n",
      "4725009  2025-01-07 10:59:30+00:00           5  0.022286     1.500000   \n",
      "4725010  2023-08-14 02:12:30+00:00           5  0.088920     1.500000   \n",
      "4725011  2023-02-03 07:52:12+00:00           5  0.027765     1.500000   \n",
      "\n",
      "         relevance  timeNorm  FinalScore   z_score  QualityCategory  \n",
      "0         0.076233  0.635752    0.565172  1.257003     High Quality  \n",
      "1         0.008955  0.658337    0.460098  0.586950  Average Quality  \n",
      "2         0.000000  0.774628    0.405825  0.240852  Average Quality  \n",
      "3         0.000000  0.722729    0.379017  0.069897  Average Quality  \n",
      "4         0.001714  0.022105    0.011594 -2.273153      Low Quality  \n",
      "...            ...       ...         ...       ...              ...  \n",
      "4725007   0.000000  0.853436    0.447212  0.504775  Average Quality  \n",
      "4725008   0.000000  0.619414    0.432786  0.412783  Average Quality  \n",
      "4725009   0.000000  0.880827    0.461423  0.595400  Average Quality  \n",
      "4725010   0.054183  0.634791    0.333841 -0.218187  Average Quality  \n",
      "4725011   0.008071  0.542528    0.284349 -0.533799  Average Quality  \n",
      "\n",
      "[4725012 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "results_z_score = compute_z_score(results_final_score)\n",
    "print(results_z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Nixon Ngai\n",
      "[nltk_data]     Weng Yue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download once\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              kind  commentId  channelId  videoId  authorId  \\\n",
      "0  youtube#comment    1781382      14492    74288   2032536   \n",
      "1  youtube#comment     289571      14727    79618   3043229   \n",
      "2  youtube#comment     569077       3314    51826    917006   \n",
      "3  youtube#comment    2957962       5008    58298   1853470   \n",
      "4  youtube#comment     673093      21411     1265   2584166   \n",
      "\n",
      "                                          textOriginal  parentCommentId  \\\n",
      "0  PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would rock it              NaN   \n",
      "1     Apply mashed potato juice and mixed it with curd        3198066.0   \n",
      "2                           69 missed calls from marsüëΩ              NaN   \n",
      "3                                                 Baaa              NaN   \n",
      "4      you look like raven from phenomena raven no cap              NaN   \n",
      "\n",
      "   likeCount                publishedAt                  updatedAt  \\\n",
      "0          0  2023-08-15 21:48:52+00:00  2023-08-15 21:48:52+00:00   \n",
      "1          0  2023-10-02 13:08:22+00:00  2023-10-02 13:08:22+00:00   \n",
      "2          0  2024-05-31 12:03:12+00:00  2024-05-31 12:03:12+00:00   \n",
      "3          0  2024-02-13 15:48:37+00:00  2024-02-13 15:48:37+00:00   \n",
      "4          0  2020-02-15 22:28:44+00:00  2020-02-15 22:28:44+00:00   \n",
      "\n",
      "   dataset_id  sentiment_score sentiment  \n",
      "0           1           0.4648  POSITIVE  \n",
      "1           1           0.0000   NEUTRAL  \n",
      "2           1          -0.2960  NEGATIVE  \n",
      "3           1           0.0000   NEUTRAL  \n",
      "4           1           0.0772  POSITIVE  \n"
     ]
    }
   ],
   "source": [
    "df_sentiment = df_all_comments.copy()\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_sentiment[\"sentiment_score\"] = df_sentiment[\"textOriginal\"].fillna(\"\").astype(str).apply(\n",
    "    lambda x: sia.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "df_sentiment[\"sentiment\"] = df_sentiment[\"sentiment_score\"].apply(\n",
    "    lambda x: \"POSITIVE\" if x > 0.05 else (\"NEGATIVE\" if x < -0.05 else \"NEUTRAL\")\n",
    ")\n",
    "\n",
    "print(df_sentiment.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
